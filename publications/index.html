<!DOCTYPE html><html lang="en" class="scroll-smooth"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/css/19bf7477d82f620e.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-679b75d1c4c2027c.js"/><script src="/_next/static/chunks/4bd1b696-70b6d399998de86a.js" async=""></script><script src="/_next/static/chunks/684-5aaa8290a129f299.js" async=""></script><script src="/_next/static/chunks/main-app-8afaf188f8f9a9ae.js" async=""></script><script src="/_next/static/chunks/17-9c04c9413a9f9f1f.js" async=""></script><script src="/_next/static/chunks/874-6cc630662f3664af.js" async=""></script><script src="/_next/static/chunks/862-15038af301665bb3.js" async=""></script><script src="/_next/static/chunks/app/layout-69018bef984bde92.js" async=""></script><script src="/_next/static/chunks/178-595a94b9af1e67b5.js" async=""></script><script src="/_next/static/chunks/748-20cf5b80cfbb8423.js" async=""></script><script src="/_next/static/chunks/app/%5Bslug%5D/page-7abd36c9556039fa.js" async=""></script><link rel="icon" href="/favicon.svg" type="image/svg+xml"/><link rel="dns-prefetch" href="https://google-fonts.jialeliu.com"/><link rel="preconnect" href="https://google-fonts.jialeliu.com" crossorigin=""/><link rel="preload" as="style" href="https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&amp;family=Crimson+Text:ital,wght@0,400;0,600;1,400&amp;display=swap"/><link rel="stylesheet" id="gfonts-css" href="https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&amp;family=Crimson+Text:ital,wght@0,400;0,600;1,400&amp;display=swap" media="print"/><script>
              (function(){
                var l = document.getElementById('gfonts-css');
                if (!l) return;
                if (l.media !== 'all') {
                  l.addEventListener('load', function(){ try { l.media = 'all'; } catch(e){} });
                }
              })();
            </script><noscript><link rel="stylesheet" href="https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&amp;family=Crimson+Text:ital,wght@0,400;0,600;1,400&amp;display=swap"/></noscript><script>
              try {
                const theme = localStorage.getItem('theme-storage');
                const parsed = theme ? JSON.parse(theme) : null;
                const setting = parsed?.state?.theme || 'system';
                const prefersDark = typeof window !== 'undefined' && window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;
                const effective = setting === 'dark' ? 'dark' : (setting === 'light' ? 'light' : (prefersDark ? 'dark' : 'light'));
                var root = document.documentElement;
                root.classList.add(effective);
                root.setAttribute('data-theme', effective);
              } catch (e) {
                var root = document.documentElement;
                root.classList.add('light');
                root.setAttribute('data-theme', 'light');
              }
            </script><title>Publications | Xu Jie 蠕先擴</title><meta name="description" content="A collection of my research work."/><meta name="author" content="Xu Jie (Rover)"/><meta name="keywords" content="Xu Jie (Rover),PhD,Research,Nanyang Technological University, Singapore"/><meta name="creator" content="Xu Jie (Rover)"/><meta name="publisher" content="Xu Jie (Rover)"/><meta property="og:title" content="Xu Jie 蠕先擴"/><meta property="og:description" content="Research Fellow at Nanyang Technological University, focusing on Embodied AI, SLAM, and multi-sensor fusion."/><meta property="og:site_name" content="Xu Jie (Rover)&#x27;s Academic Website"/><meta property="og:locale" content="en_US"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Xu Jie 蠕先擴"/><meta name="twitter:description" content="Research Fellow at Nanyang Technological University, focusing on Embodied AI, SLAM, and multi-sensor fusion."/><link rel="icon" href="/favicon.svg"/><script>document.querySelectorAll('body link[rel="icon"], body link[rel="apple-touch-icon"]').forEach(el => document.head.appendChild(el))</script><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="font-sans antialiased"><div style="visibility:hidden"><nav class="fixed top-0 left-0 right-0 z-50" data-headlessui-state=""><div class="transition-all duration-300 ease-out bg-transparent" style="transform:translateY(-100px)"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="flex justify-between items-center h-16 lg:h-20"><div class="flex-shrink-0" tabindex="0"><a class="text-xl lg:text-2xl font-serif font-semibold text-primary hover:text-accent transition-colors duration-200" href="/">Xu Jie 蠕先擴</a></div><div class="hidden lg:block"><div class="ml-10 flex items-center space-x-8"><div class="flex items-baseline space-x-8"><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm text-neutral-600 hover:text-primary" href="/"><span class="relative z-10">About</span></a><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm text-primary" href="/publications/"><span class="relative z-10">Publications</span><div class="absolute inset-0 bg-accent/10 rounded-lg"></div></a><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm text-neutral-600 hover:text-primary" href="/cv/"><span class="relative z-10">CV</span></a></div><div class="flex items-center justify-center w-10 h-10 rounded-lg border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] bg-background dark:bg-neutral-800"><div class="w-4 h-4 rounded-full bg-neutral-300 animate-pulse"></div></div></div></div><div class="lg:hidden flex items-center space-x-2"><div class="flex items-center justify-center w-10 h-10 rounded-lg border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] bg-background dark:bg-neutral-800"><div class="w-4 h-4 rounded-full bg-neutral-300 animate-pulse"></div></div><button class="inline-flex items-center justify-center p-2 rounded-md text-neutral-600 hover:text-primary hover:bg-neutral-100 dark:hover:bg-neutral-800 focus:outline-none focus:ring-2 focus:ring-inset focus:ring-accent transition-colors duration-200" id="headlessui-disclosure-button-ﾂｫR5pdbﾂｻ" type="button" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Open main menu</span><div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="block h-6 w-6"><path stroke-linecap="round" stroke-linejoin="round" d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5"></path></svg></div></button></div></div></div></div></nav><main class="min-h-screen pt-16 lg:pt-20"><div class="max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 py-12"><div style="opacity:0;transform:translateY(20px)"><div class="mb-8"><h1 class="text-4xl font-serif font-bold text-primary mb-4">Publications</h1><p class="text-lg text-neutral-600 dark:text-neutral-500 max-w-2xl">A collection of my research work.</p></div><div class="mb-8 space-y-4"><div class="flex flex-col sm:flex-row gap-4"><div class="relative flex-grow"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="absolute left-3 top-1/2 transform -translate-y-1/2 h-5 w-5 text-neutral-400"><path stroke-linecap="round" stroke-linejoin="round" d="m21 21-5.197-5.197m0 0A7.5 7.5 0 1 0 5.196 5.196a7.5 7.5 0 0 0 10.607 10.607Z"></path></svg><input type="text" placeholder="Search publications..." class="w-full pl-10 pr-4 py-2 rounded-lg border border-neutral-200 dark:border-neutral-800 bg-white dark:bg-neutral-900 focus:ring-2 focus:ring-accent focus:border-transparent transition-all duration-200" value=""/></div><button class="flex items-center justify-center px-4 py-2 rounded-lg border transition-all duration-200 bg-white dark:bg-neutral-900 border-neutral-200 dark:border-neutral-800 text-neutral-600 hover:border-accent hover:text-accent"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-5 w-5 mr-2"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3c2.755 0 5.455.232 8.083.678.533.09.917.556.917 1.096v1.044a2.25 2.25 0 0 1-.659 1.591l-5.432 5.432a2.25 2.25 0 0 0-.659 1.591v2.927a2.25 2.25 0 0 1-1.244 2.013L9.75 21v-6.568a2.25 2.25 0 0 0-.659-1.591L3.659 7.409A2.25 2.25 0 0 1 3 5.818V4.774c0-.54.384-1.006.917-1.096A48.32 48.32 0 0 1 12 3Z"></path></svg>Filters</button></div></div><div class="space-y-6"><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="w-full md:w-48 flex-shrink-0"><div class="aspect-video md:aspect-[4/3] relative rounded-lg overflow-hidden bg-neutral-100 dark:bg-neutral-800"><img alt="MM-LINS: A Multi-Map LiDAR-Inertial System for Over-Degenerate Environments" loading="lazy" decoding="async" data-nimg="fill" class="object-cover" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/mm-lins.png"/></div></div><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">MM-LINS: A Multi-Map LiDAR-Inertial System for Over-Degenerate Environments</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class="">Yongxin Ma</span>, </span><span><span class="font-semibold text-accent">Jie Xu (co-first)</span>, </span><span><span class="">Shenghai Yuan</span>, </span><span><span class="">Tian Zhi</span>, </span><span><span class="">Wenlu Yu</span>, </span><span><span class="">Jun Zhou</span>, </span><span><span class="">Lihua Xie</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3">IEEE Transactions on Intelligent Vehicles<!-- --> <!-- -->2025</p><div class="flex flex-wrap gap-2 mt-auto"><a href="https://doi.org/10.1109/TIV.2024.3414852" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">DOI</a><a href="https://github.com/lian-yue0515/MM-LINS" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Code</a><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button><a href="https://www.bilibili.com/video/BV1eC4y1Z7qk?spm_id_from=333.788.recommend_more_video.2&amp;trackid=web_related_0.router-related-2206419-t6cb9.1764574640193.524&amp;vd_source=24dbe70b6e5bca1edf14deb9a2f63088" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Video</a></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="w-full md:w-48 flex-shrink-0"><div class="aspect-video md:aspect-[4/3] relative rounded-lg overflow-hidden bg-neutral-100 dark:bg-neutral-800"><img alt="Adaptive-LIO: Enhancing Robustness and Precision Through Environmental Adaptation in LiDAR Inertial Odometry" loading="lazy" decoding="async" data-nimg="fill" class="object-cover" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/Adaptivelio.png"/></div></div><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">Adaptive-LIO: Enhancing Robustness and Precision Through Environmental Adaptation in LiDAR Inertial Odometry</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class="">Chengwei Zhao</span>, </span><span><span class="">Kun Hu</span>, </span><span><span class="font-semibold text-accent">Jie Xu (Corresponding)</span>, </span><span><span class="">Lijun Zhao</span>, </span><span><span class="">Baiwen Han</span>, </span><span><span class="">Kaidi Wu</span>, </span><span><span class="">Maoshan Tian</span>, </span><span><span class="">Shenghai Yuan</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3">IEEE Internet of Things Journal<!-- --> <!-- -->2025</p><div class="flex flex-wrap gap-2 mt-auto"><a href="https://doi.org/10.1109/JIOT.2024.3519533" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">DOI</a><a href="https://github.com/chengwei0427/Adaptive-LIO" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Code</a><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="w-full md:w-48 flex-shrink-0"><div class="aspect-video md:aspect-[4/3] relative rounded-lg overflow-hidden bg-neutral-100 dark:bg-neutral-800"><img alt="UAPGO: Uncertainty-Aware Pose Graph Optimization for LiDAR-Based SLAM Systems" loading="lazy" decoding="async" data-nimg="fill" class="object-cover" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/uncertainty.png"/></div></div><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">UAPGO: Uncertainty-Aware Pose Graph Optimization for LiDAR-Based SLAM Systems</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class="">Tian Zhi</span>, </span><span><span class="font-semibold text-accent">Jie Xu (Co-first)</span>, </span><span><span class="">Yongxin Ma</span>, </span><span><span class="">Wenlu Yu</span>, </span><span><span class="">Shenglan Liu</span>, </span><span><span class="">Shenghai Yuan</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3">Yongxin and Yu, Wenlu and Liu, Shenglan and Yuan, Shenghai, Uapgo: Uncertainty-Aware Pose Graph Optimization for Lidar-Based Slam Systems<!-- --> <!-- -->2025</p><div class="flex flex-wrap gap-2 mt-auto"><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="w-full md:w-48 flex-shrink-0"><div class="aspect-video md:aspect-[4/3] relative rounded-lg overflow-hidden bg-neutral-100 dark:bg-neutral-800"><img alt="II-NVM: Enhancing Map Accuracy and Consistency With Normal Vector-Assisted Mapping" loading="lazy" decoding="async" data-nimg="fill" class="object-cover" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/ii-nvm.jpg"/></div></div><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">II-NVM: Enhancing Map Accuracy and Consistency With Normal Vector-Assisted Mapping</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class="">Chengwei Zhao</span>, </span><span><span class="">Yixuan Li</span>, </span><span><span class="">Yina Jian</span>, </span><span><span class="font-semibold text-accent">Jie Xu (Corresponding)</span>, </span><span><span class="">Linji Wang</span>, </span><span><span class="">Yongxin Ma</span>, </span><span><span class="">Xinglai Jin</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3">IEEE Robotics and Automation Letters<!-- --> <!-- -->2025</p><div class="flex flex-wrap gap-2 mt-auto"><a href="https://doi.org/10.1109/LRA.2025.3561568" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">DOI</a><a href="https://github.com/chengwei0427/II-NVM" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Code</a><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button><a href="https://www.bilibili.com/video/BV12KLvzFEGh/?spm_id_from=333.1387.homepage.video_card.click&amp;vd_source=24dbe70b6e5bca1edf14deb9a2f63088" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Video</a></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="w-full md:w-48 flex-shrink-0"><div class="aspect-video md:aspect-[4/3] relative rounded-lg overflow-hidden bg-neutral-100 dark:bg-neutral-800"><img alt="Dynamic Initialization for LiDAR-Inertial SLAM" loading="lazy" decoding="async" data-nimg="fill" class="object-cover" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/dliinit.pdf"/></div></div><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">Dynamic Initialization for LiDAR-Inertial SLAM</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class="font-semibold text-accent">Jie Xu</span>, </span><span><span class="">Yongxin Ma</span>, </span><span><span class="">Yixuan Li</span>, </span><span><span class="">Xuanxuan Zhang</span>, </span><span><span class="">Jun Zhou</span>, </span><span><span class="">Shenghai Yuan</span>, </span><span><span class="">Lihua Xie</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3">IEEE/ASME Transactions on Mechatronics<!-- --> <!-- -->2025</p><div class="flex flex-wrap gap-2 mt-auto"><a href="https://doi.org/10.1109/TMECH.2025.3554878" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">DOI</a><a href="https://github.com/lian-yue0515/D-LI-Init" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Code</a><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="w-full md:w-48 flex-shrink-0"><div class="aspect-video md:aspect-[4/3] relative rounded-lg overflow-hidden bg-neutral-100 dark:bg-neutral-800"><img alt="LiDAR-Link: Observability-Aware Probabilistic Plane-Based Extrinsic Calibration for Non-Overlapping Solid-State LiDARs" loading="lazy" decoding="async" data-nimg="fill" class="object-cover" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/lidarlink.png"/></div></div><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">LiDAR-Link: Observability-Aware Probabilistic Plane-Based Extrinsic Calibration for Non-Overlapping Solid-State LiDARs</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class="font-semibold text-accent">Jie Xu</span>, </span><span><span class="">Song Huang</span>, </span><span><span class="">Shuxin Qiu</span>, </span><span><span class="">Lijun Zhao</span>, </span><span><span class="">Wenlu Yu</span>, </span><span><span class="">Mingxing Fang</span>, </span><span><span class="">Minhang Wang</span>, </span><span><span class="">Ruifeng Li</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3">IEEE Robotics and Automation Letters<!-- --> <!-- -->2024</p><div class="flex flex-wrap gap-2 mt-auto"><a href="https://doi.org/10.1109/LRA.2024.3355733" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">DOI</a><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="w-full md:w-48 flex-shrink-0"><div class="aspect-video md:aspect-[4/3] relative rounded-lg overflow-hidden bg-neutral-100 dark:bg-neutral-800"><img alt="I2EKF-LO: A Dual-Iteration Extended Kalman Filter Based LiDAR Odometry" loading="lazy" decoding="async" data-nimg="fill" class="object-cover" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/i2ekf.png"/></div></div><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">I2EKF-LO: A Dual-Iteration Extended Kalman Filter Based LiDAR Odometry</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class="">Wenlu Yu</span>, </span><span><span class="font-semibold text-accent">Jie Xu (co-first)</span>, </span><span><span class="">Chengwei Zhao</span>, </span><span><span class="">Lijun Zhao</span>, </span><span><span class="">Thien-Minh Nguyen</span>, </span><span><span class="">Shenghai Yuan</span>, </span><span><span class="">Mingming Bai</span>, </span><span><span class="">Lihua Xie</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3">2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)<!-- --> <!-- -->2024</p><div class="flex flex-wrap gap-2 mt-auto"><a href="https://doi.org/10.1109/IROS58592.2024.10801455" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">DOI</a><a href="https://github.com/YWL0720/I2EKF-LO" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Code</a><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button><a href="https://www.bilibili.com/video/BV1em421g74N/?spm_id_from=333.337.search-card.all.click&amp;vd_source=24dbe70b6e5bca1edf14deb9a2f63088" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Video</a></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="w-full md:w-48 flex-shrink-0"><div class="aspect-video md:aspect-[4/3] relative rounded-lg overflow-hidden bg-neutral-100 dark:bg-neutral-800"><img alt="M-DIVO: Multiple ToF RGB-D Cameras-Enhanced Depth窶的nertial窶天isual Odometry" loading="lazy" decoding="async" data-nimg="fill" class="object-cover" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/mdivo.png"/></div></div><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">M-DIVO: Multiple ToF RGB-D Cameras-Enhanced Depth窶的nertial窶天isual Odometry</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class="font-semibold text-accent">Jie Xu</span>, </span><span><span class="">Wenlu Yu</span>, </span><span><span class="">Song Huang</span>, </span><span><span class="">Shenghai Yuan</span>, </span><span><span class="">Lijun Zhao</span>, </span><span><span class="">Ruifeng Li</span>, </span><span><span class="">Lihua Xie</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3">IEEE Internet of Things Journal<!-- --> <!-- -->2024</p><div class="flex flex-wrap gap-2 mt-auto"><a href="https://doi.org/10.1109/JIOT.2024.3434588" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">DOI</a><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="w-full md:w-48 flex-shrink-0"><div class="aspect-video md:aspect-[4/3] relative rounded-lg overflow-hidden bg-neutral-100 dark:bg-neutral-800"><img alt="Selective Kalman Filter: When and How to Fuse Multi-Sensor Information to Overcome Degeneracy in SLAM" loading="lazy" decoding="async" data-nimg="fill" class="object-cover" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/selective.png"/></div></div><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">Selective Kalman Filter: When and How to Fuse Multi-Sensor Information to Overcome Degeneracy in SLAM</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class="font-semibold text-accent">Jie Xu</span>, </span><span><span class="">Guanyu Huang</span>, </span><span><span class="">Wenlu Yu</span>, </span><span><span class="">Xuanxuan Zhang</span>, </span><span><span class="">Lijun Zhao</span>, </span><span><span class="">Ruifeng Li</span>, </span><span><span class="">Shenghai Yuan</span>, </span><span><span class="">Lihua Xie</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3">arXiv preprint arXiv:2412.17235<!-- --> <!-- -->2024</p><div class="flex flex-wrap gap-2 mt-auto"><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="w-full md:w-48 flex-shrink-0"><div class="aspect-video md:aspect-[4/3] relative rounded-lg overflow-hidden bg-neutral-100 dark:bg-neutral-800"><img alt="R2DIO: A Robust and Real-Time Depth-Inertial Odometry Leveraging Multimodal Constraints for Challenging Environments" loading="lazy" decoding="async" data-nimg="fill" class="object-cover" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/r2dio.png"/></div></div><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">R2DIO: A Robust and Real-Time Depth-Inertial Odometry Leveraging Multimodal Constraints for Challenging Environments</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class="font-semibold text-accent">Jie Xu</span>, </span><span><span class="">Ruifeng Li</span>, </span><span><span class="">Song Huang</span>, </span><span><span class="">Xiongwei Zhao</span>, </span><span><span class="">Shuxin Qiu</span>, </span><span><span class="">Zhijun Chen</span>, </span><span><span class="">Lijun Zhao</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3">IEEE Transactions on Instrumentation and Measurement<!-- --> <!-- -->2023</p><div class="flex flex-wrap gap-2 mt-auto"><a href="https://doi.org/10.1109/TIM.2023.3320753" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">DOI</a><a href="https://github.com/jiejie567/R2DIO" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Code</a><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button><a href="https://www.youtube.com/watch?v=YqJZTE948sk" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Video</a></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="w-full md:w-48 flex-shrink-0"><div class="aspect-video md:aspect-[4/3] relative rounded-lg overflow-hidden bg-neutral-100 dark:bg-neutral-800"><img alt="CamMap: Extrinsic Calibration of Non-Overlapping Cameras Based on SLAM Map Alignment" loading="lazy" decoding="async" data-nimg="fill" class="object-cover" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/cammap.png"/></div></div><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">CamMap: Extrinsic Calibration of Non-Overlapping Cameras Based on SLAM Map Alignment</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class="font-semibold text-accent">Jie Xu</span>, </span><span><span class="">Ruifeng Li</span>, </span><span><span class="">Lijun Zhao</span>, </span><span><span class="">Wenlu Yu</span>, </span><span><span class="">Zhiheng Liu</span>, </span><span><span class="">Bo Zhang</span>, </span><span><span class="">Yuchen Li</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3">IEEE Robotics and Automation Letters<!-- --> <!-- -->2022</p><div class="flex flex-wrap gap-2 mt-auto"><a href="https://doi.org/10.1109/LRA.2022.3207793" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">DOI</a><a href="https://github.com/jiejie567/SlamForCalib" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Code</a><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button><a href="https://www.bilibili.com/video/BV1XJ4m1T7Qv/?spm_id_from=333.337.search-card.all.click&amp;vd_source=24dbe70b6e5bca1edf14deb9a2f63088" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white transition-colors">Video</a></div></div></div></div></div></div></div><!--$--><!--/$--><!--$--><!--/$--></main><footer class="border-t border-neutral-200/50 bg-neutral-50/50 dark:bg-neutral-900/50 dark:border-neutral-700/50"><div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-6"><div class="flex flex-col sm:flex-row justify-between items-center gap-2"><p class="text-xs text-neutral-500">Last updated: <!-- -->December 01, 2025</p><p class="text-xs text-neutral-500 flex items-center"><a href="https://github.com/xyjoey/PRISM" target="_blank" rel="noopener noreferrer">Built with PRISM</a><span class="ml-2">泅</span></p></div></div></footer></div><script src="/_next/static/chunks/webpack-679b75d1c4c2027c.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[3719,[\"17\",\"static/chunks/17-9c04c9413a9f9f1f.js\",\"874\",\"static/chunks/874-6cc630662f3664af.js\",\"862\",\"static/chunks/862-15038af301665bb3.js\",\"177\",\"static/chunks/app/layout-69018bef984bde92.js\"],\"ThemeProvider\"]\n3:I[768,[\"17\",\"static/chunks/17-9c04c9413a9f9f1f.js\",\"874\",\"static/chunks/874-6cc630662f3664af.js\",\"862\",\"static/chunks/862-15038af301665bb3.js\",\"177\",\"static/chunks/app/layout-69018bef984bde92.js\"],\"default\"]\n4:I[7555,[],\"\"]\n5:I[1295,[],\"\"]\n6:I[2548,[\"17\",\"static/chunks/17-9c04c9413a9f9f1f.js\",\"874\",\"static/chunks/874-6cc630662f3664af.js\",\"862\",\"static/chunks/862-15038af301665bb3.js\",\"177\",\"static/chunks/app/layout-69018bef984bde92.js\"],\"default\"]\n8:I[9665,[],\"MetadataBoundary\"]\na:I[9665,[],\"OutletBoundary\"]\nd:I[4911,[],\"AsyncMetadataOutlet\"]\nf:I[9665,[],\"ViewportBoundary\"]\n11:I[6614,[],\"\"]\n:HL[\"/_next/static/css/19bf7477d82f620e.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"D7FRJMzCgrrqXrr6gVvn3\",\"p\":\"\",\"c\":[\"\",\"publications\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[[\"slug\",\"publications\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/19bf7477d82f620e.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"scroll-smooth\",\"suppressHydrationWarning\":true,\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"link\",null,{\"rel\":\"icon\",\"href\":\"/favicon.svg\",\"type\":\"image/svg+xml\"}],[\"$\",\"link\",null,{\"rel\":\"dns-prefetch\",\"href\":\"https://google-fonts.jialeliu.com\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://google-fonts.jialeliu.com\",\"crossOrigin\":\"\"}],[\"$\",\"link\",null,{\"rel\":\"preload\",\"as\":\"style\",\"href\":\"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700\u0026family=Crimson+Text:ital,wght@0,400;0,600;1,400\u0026display=swap\"}],[\"$\",\"link\",null,{\"rel\":\"stylesheet\",\"id\":\"gfonts-css\",\"href\":\"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700\u0026family=Crimson+Text:ital,wght@0,400;0,600;1,400\u0026display=swap\",\"media\":\"print\"}],[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\n              (function(){\\n                var l = document.getElementById('gfonts-css');\\n                if (!l) return;\\n                if (l.media !== 'all') {\\n                  l.addEventListener('load', function(){ try { l.media = 'all'; } catch(e){} });\\n                }\\n              })();\\n            \"}}],[\"$\",\"noscript\",null,{\"children\":[\"$\",\"link\",null,{\"rel\":\"stylesheet\",\"href\":\"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700\u0026family=Crimson+Text:ital,wght@0,400;0,600;1,400\u0026display=swap\"}]}],[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\n              try {\\n                const theme = localStorage.getItem('theme-storage');\\n                const parsed = theme ? JSON.parse(theme) : null;\\n                const setting = parsed?.state?.theme || 'system';\\n                const prefersDark = typeof window !== 'undefined' \u0026\u0026 window.matchMedia \u0026\u0026 window.matchMedia('(prefers-color-scheme: dark)').matches;\\n                const effective = setting === 'dark' ? 'dark' : (setting === 'light' ? 'light' : (prefersDark ? 'dark' : 'light'));\\n                var root = document.documentElement;\\n                root.classList.add(effective);\\n                root.setAttribute('data-theme', effective);\\n              } catch (e) {\\n                var root = document.documentElement;\\n                root.classList.add('light');\\n                root.setAttribute('data-theme', 'light');\\n              }\\n            \"}}]]}],[\"$\",\"body\",null,{\"className\":\"font-sans antialiased\",\"children\":[\"$\",\"$L2\",null,{\"children\":[[\"$\",\"$L3\",null,{\"items\":[{\"title\":\"About\",\"type\":\"page\",\"target\":\"about\",\"href\":\"/\"},{\"title\":\"Publications\",\"type\":\"page\",\"target\":\"publications\",\"href\":\"/publications\"},{\"title\":\"CV\",\"type\":\"page\",\"target\":\"cv\",\"href\":\"/cv\"}],\"siteTitle\":\"Xu Jie 蠕先擴\",\"enableOnePageMode\":false}],[\"$\",\"main\",null,{\"className\":\"min-h-screen pt-16 lg:pt-20\",\"children\":[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}],[\"$\",\"$L6\",null,{\"lastUpdated\":\"December 01, 2025\"}]]}]}]]}]]}],{\"children\":[[\"slug\",\"publications\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L7\",[\"$\",\"$L8\",null,{\"children\":\"$L9\"}],null,[\"$\",\"$La\",null,{\"children\":[\"$Lb\",\"$Lc\",[\"$\",\"$Ld\",null,{\"promise\":\"$@e\"}]]}]]}],{},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"tuZje1idN8YWsfFe8wNOD\",{\"children\":[[\"$\",\"$Lf\",null,{\"children\":\"$L10\"}],null]}],null]}],false]],\"m\":\"$undefined\",\"G\":[\"$11\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"12:\"$Sreact.suspense\"\n13:I[4911,[],\"AsyncMetadata\"]\n15:I[6669,[\"17\",\"static/chunks/17-9c04c9413a9f9f1f.js\",\"178\",\"static/chunks/178-595a94b9af1e67b5.js\",\"748\",\"static/chunks/748-20cf5b80cfbb8423.js\",\"182\",\"static/chunks/app/%5Bslug%5D/page-7abd36c9556039fa.js\"],\"default\"]\n9:[\"$\",\"$12\",null,{\"fallback\":null,\"children\":[\"$\",\"$L13\",null,{\"promise\":\"$@14\"}]}]\n"])</script><script>self.__next_f.push([1,"7:[\"$\",\"div\",null,{\"className\":\"max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 py-12\",\"children\":[[\"$\",\"$L15\",null,{\"config\":{\"type\":\"publication\",\"title\":\"Publications\",\"description\":\"A collection of my research work.\",\"source\":\"publications.bib\"},\"publications\":[{\"id\":\"ma2024mm\",\"title\":\"MM-LINS: A Multi-Map LiDAR-Inertial System for Over-Degenerate Environments\",\"authors\":[{\"name\":\"Yongxin Ma\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Jie Xu (co-first)\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Shenghai Yuan\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Tian Zhi\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Wenlu Yu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Jun Zhou\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Lihua Xie\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2025,\"type\":\"journal\",\"status\":\"published\",\"tags\":[\"Simultaneous localization and mapping;Laser radar;Trajectory;Accuracy;Vehicle dynamics;Intelligent vehicles;Sensor phenomena and characterization;Multi-map;over-degenerate;pose graph optimization;simultaneous location and mapping\"],\"keywords\":\"$7:props:children:0:props:publications:0:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"IEEE Transactions on Intelligent Vehicles\",\"conference\":\"\",\"volume\":\"10\",\"issue\":\"1\",\"pages\":\"472-482\",\"doi\":\"10.1109/TIV.2024.3414852\",\"code\":\"https://github.com/lian-yue0515/MM-LINS\",\"abstract\":\"\",\"description\":\"\",\"selected\":false,\"preview\":\"mm-lins.png\",\"video\":\"https://www.bilibili.com/video/BV1eC4y1Z7qk?spm_id_from=333.788.recommend_more_video.2\u0026trackid=web_related_0.router-related-2206419-t6cb9.1764574640193.524\u0026vd_source=24dbe70b6e5bca1edf14deb9a2f63088\",\"bibtex\":\"@article{ma2024mm,\\n  author = {Ma, Yongxin and Jie Xu (co-first) and Yuan, Shenghai and Zhi, Tian and Yu, Wenlu and Zhou, Jun and Xie, Lihua},\\n  journal = {IEEE Transactions on Intelligent Vehicles},\\n  title = {MM-LINS: A Multi-Map LiDAR-Inertial System for Over-Degenerate Environments},\\n  year = {2025},\\n  volume = {10},\\n  number = {1},\\n  pages = {472-482},\\n  doi = {10.1109/TIV.2024.3414852},\\n  video = {https://www.bilibili.com/video/BV1eC4y1Z7qk?spm_id_from=333.788.recommend_more_video.2\u0026trackid=web_related_0.router-related-2206419-t6cb9.1764574640193.524\u0026vd_source=24dbe70b6e5bca1edf14deb9a2f63088}\\n}\"},{\"id\":\"10806842\",\"title\":\"Adaptive-LIO: Enhancing Robustness and Precision Through Environmental Adaptation in LiDAR Inertial Odometry\",\"authors\":[{\"name\":\"Chengwei Zhao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Kun Hu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Jie Xu (Corresponding)\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Lijun Zhao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Baiwen Han\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Kaidi Wu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Maoshan Tian\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Shenghai Yuan\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2025,\"type\":\"journal\",\"status\":\"published\",\"tags\":[\"Accuracy;Laser radar;Odometry;Motion segmentation;Simultaneous localization and mapping;Internet of Things;Robots;Feature extraction;Trajectory;Robustness;Adaptive;LiDAR inertial odometry (LIO);multiresolution map;SLAM\"],\"keywords\":\"$7:props:children:0:props:publications:1:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"IEEE Internet of Things Journal\",\"conference\":\"\",\"volume\":\"12\",\"issue\":\"9\",\"pages\":\"12123-12136\",\"doi\":\"10.1109/JIOT.2024.3519533\",\"code\":\"https://github.com/chengwei0427/Adaptive-LIO\",\"abstract\":\"\",\"description\":\"\",\"selected\":false,\"preview\":\"Adaptivelio.png\",\"bibtex\":\"@ARTICLE{10806842,\\n  author = {Zhao, Chengwei and Hu, Kun and Jie Xu (Corresponding) and Zhao, Lijun and Han, Baiwen and Wu, Kaidi and Tian, Maoshan and Yuan, Shenghai},\\n  journal = {IEEE Internet of Things Journal},\\n  title = {Adaptive-LIO: Enhancing Robustness and Precision Through Environmental Adaptation in LiDAR Inertial Odometry},\\n  year = {2025},\\n  volume = {12},\\n  number = {9},\\n  pages = {12123-12136},\\n  doi = {10.1109/JIOT.2024.3519533}\\n}\"},{\"id\":\"zhiuapgo\",\"title\":\"UAPGO: Uncertainty-Aware Pose Graph Optimization for LiDAR-Based SLAM Systems\",\"authors\":[{\"name\":\"Tian Zhi\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Jie Xu (Co-first)\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yongxin Ma\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Wenlu Yu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Shenglan Liu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Shenghai Yuan\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2025,\"type\":\"journal\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$7:props:children:0:props:publications:2:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"Yongxin and Yu, Wenlu and Liu, Shenglan and Yuan, Shenghai, Uapgo: Uncertainty-Aware Pose Graph Optimization for Lidar-Based Slam Systems\",\"conference\":\"\",\"abstract\":\"\",\"description\":\"\",\"selected\":false,\"preview\":\"uncertainty.png\",\"bibtex\":\"@article{zhiuapgo,\\n  title = {UAPGO: Uncertainty-Aware Pose Graph Optimization for LiDAR-Based SLAM Systems},\\n  author = {Zhi, Tian and Jie Xu (Co-first) and Ma, Yongxin and Yu, Wenlu and Liu, Shenglan and Yuan, Shenghai},\\n  journal = {Yongxin and Yu, Wenlu and Liu, Shenglan and Yuan, Shenghai, Uapgo: Uncertainty-Aware Pose Graph Optimization for Lidar-Based Slam Systems}\\n}\"},{\"id\":\"zhao2025ii\",\"title\":\"II-NVM: Enhancing Map Accuracy and Consistency With Normal Vector-Assisted Mapping\",\"authors\":[{\"name\":\"Chengwei Zhao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yixuan Li\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yina Jian\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Jie Xu (Corresponding)\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Linji Wang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yongxin Ma\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xinglai Jin\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2025,\"type\":\"journal\",\"status\":\"published\",\"tags\":[\"Vectors;Point cloud compression;Accuracy;Simultaneous localization and mapping;Laser radar;Real-time systems;Pose estimation;Odometry;Data mining;Artificial intelligence;SLAM;Mapping;indoor;double-sided mapping issue;normal vector-assisted\"],\"keywords\":\"$7:props:children:0:props:publications:3:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"IEEE Robotics and Automation Letters\",\"conference\":\"\",\"volume\":\"10\",\"issue\":\"6\",\"pages\":\"5465-5472\",\"doi\":\"10.1109/LRA.2025.3561568\",\"code\":\"https://github.com/chengwei0427/II-NVM\",\"abstract\":\"\",\"description\":\"\",\"selected\":true,\"preview\":\"ii-nvm.jpg\",\"video\":\"https://www.bilibili.com/video/BV12KLvzFEGh/?spm_id_from=333.1387.homepage.video_card.click\u0026vd_source=24dbe70b6e5bca1edf14deb9a2f63088\",\"bibtex\":\"@article{zhao2025ii,\\n  author = {Zhao, Chengwei and Li, Yixuan and Jian, Yina and Jie Xu (Corresponding) and Wang, Linji and Ma, Yongxin and Jin, Xinglai},\\n  journal = {IEEE Robotics and Automation Letters},\\n  title = {II-NVM: Enhancing Map Accuracy and Consistency With Normal Vector-Assisted Mapping},\\n  year = {2025},\\n  volume = {10},\\n  number = {6},\\n  pages = {5465-5472},\\n  doi = {10.1109/LRA.2025.3561568},\\n  video = {https://www.bilibili.com/video/BV12KLvzFEGh/?spm_id_from=333.1387.homepage.video_card.click\u0026vd_source=24dbe70b6e5bca1edf14deb9a2f63088}\\n}\"},{\"id\":\"xu2025dynamic\",\"title\":\"Dynamic Initialization for LiDAR-Inertial SLAM\",\"authors\":[{\"name\":\"Jie Xu\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yongxin Ma\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yixuan Li\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xuanxuan Zhang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Jun Zhou\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Shenghai Yuan\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Lihua Xie\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2025,\"type\":\"journal\",\"status\":\"published\",\"tags\":[\"Odometry;Laser radar;Simultaneous localization and mapping;Accuracy;Vehicle dynamics;Gyroscopes;Gravity;Point cloud compression;Distortion;State estimation;Dynamic initialization;LiDAR-gyroscope odometry;LiDAR-inertial;simultaneous location and mapping (SLAM)\"],\"keywords\":\"$7:props:children:0:props:publications:4:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"IEEE/ASME Transactions on Mechatronics\",\"conference\":\"\",\"volume\":\"\",\"issue\":\"\",\"pages\":\"1-12\",\"doi\":\"10.1109/TMECH.2025.3554878\",\"code\":\"https://github.com/lian-yue0515/D-LI-Init\",\"abstract\":\"\",\"description\":\"\",\"selected\":true,\"preview\":\"dliinit.pdf\",\"bibtex\":\"@article{xu2025dynamic,\\n  author = {Xu, Jie and Ma, Yongxin and Li, Yixuan and Zhang, Xuanxuan and Zhou, Jun and Yuan, Shenghai and Xie, Lihua},\\n  journal = {IEEE/ASME Transactions on Mechatronics},\\n  title = {Dynamic Initialization for LiDAR-Inertial SLAM},\\n  year = {2025},\\n  volume = {},\\n  number = {},\\n  pages = {1-12},\\n  doi = {10.1109/TMECH.2025.3554878}\\n}\"},{\"id\":\"xu2024lidar\",\"title\":\"LiDAR-Link: Observability-Aware Probabilistic Plane-Based Extrinsic Calibration for Non-Overlapping Solid-State LiDARs\",\"authors\":[{\"name\":\"Jie Xu\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Song Huang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Shuxin Qiu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Lijun Zhao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Wenlu Yu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Mingxing Fang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Minhang Wang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Ruifeng Li\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2024,\"type\":\"journal\",\"status\":\"published\",\"tags\":[\"LiDAR;Calibration;Point cloud compression;Sensors;Bridges;Probabilistic logic;Robot kinematics;Observability-aware;solid-state LiDAR;non-overlapping;extrinsic calibration;probabilistic plane;IEKF\"],\"keywords\":\"$7:props:children:0:props:publications:5:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"IEEE Robotics and Automation Letters\",\"conference\":\"\",\"volume\":\"9\",\"issue\":\"3\",\"pages\":\"2590-2597\",\"doi\":\"10.1109/LRA.2024.3355733\",\"abstract\":\"\",\"description\":\"\",\"selected\":false,\"preview\":\"lidarlink.png\",\"bibtex\":\"@article{xu2024lidar,\\n  author = {Xu, Jie and Huang, Song and Qiu, Shuxin and Zhao, Lijun and Yu, Wenlu and Fang, Mingxing and Wang, Minhang and Li, Ruifeng},\\n  journal = {IEEE Robotics and Automation Letters},\\n  title = {LiDAR-Link: Observability-Aware Probabilistic Plane-Based Extrinsic Calibration for Non-Overlapping Solid-State LiDARs},\\n  year = {2024},\\n  volume = {9},\\n  number = {3},\\n  pages = {2590-2597},\\n  doi = {10.1109/LRA.2024.3355733}\\n}\"},{\"id\":\"yu20242\",\"title\":\"I2EKF-LO: A Dual-Iteration Extended Kalman Filter Based LiDAR Odometry\",\"authors\":[{\"name\":\"Wenlu Yu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Jie Xu (co-first)\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Chengwei Zhao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Lijun Zhao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Thien-Minh Nguyen\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Shenghai Yuan\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Mingming Bai\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Lihua Xie\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2024,\"type\":\"conference\",\"status\":\"published\",\"tags\":[\"Point cloud compression;Laser radar;Accuracy;Nonlinear distortion;Noise;Robot sensing systems;Mathematical models;Odometry;Kalman filters;State estimation\"],\"keywords\":\"$7:props:children:0:props:publications:6:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"\",\"conference\":\"2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"volume\":\"\",\"issue\":\"\",\"pages\":\"10453-10460\",\"doi\":\"10.1109/IROS58592.2024.10801455\",\"code\":\"https://github.com/YWL0720/I2EKF-LO\",\"abstract\":\"\",\"description\":\"\",\"selected\":true,\"preview\":\"i2ekf.png\",\"video\":\"https://www.bilibili.com/video/BV1em421g74N/?spm_id_from=333.337.search-card.all.click\u0026vd_source=24dbe70b6e5bca1edf14deb9a2f63088\",\"bibtex\":\"@inproceedings{yu20242,\\n  author = {Yu, Wenlu and Jie Xu (co-first) and Zhao, Chengwei and Zhao, Lijun and Nguyen, Thien-Minh and Yuan, Shenghai and Bai, Mingming and Xie, Lihua},\\n  booktitle = {2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},\\n  title = {I2EKF-LO: A Dual-Iteration Extended Kalman Filter Based LiDAR Odometry},\\n  year = {2024},\\n  volume = {},\\n  number = {},\\n  pages = {10453-10460},\\n  doi = {10.1109/IROS58592.2024.10801455},\\n  video = {https://www.bilibili.com/video/BV1em421g74N/?spm_id_from=333.337.search-card.all.click\u0026vd_source=24dbe70b6e5bca1edf14deb9a2f63088}\\n}\"},{\"id\":\"xu2024m\",\"title\":\"M-DIVO: Multiple ToF RGB-D Cameras-Enhanced Depth窶的nertial窶天isual Odometry\",\"authors\":[{\"name\":\"Jie Xu\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Wenlu Yu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Song Huang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Shenghai Yuan\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Lijun Zhao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Ruifeng Li\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Lihua Xie\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2024,\"type\":\"journal\",\"status\":\"published\",\"tags\":[\"Simultaneous localization and mapping;Cameras;Laser radar;Calibration;Sensors;Visualization;Accuracy;Calibration;degeneracy;multimodal;SLAM;Time-of-Flight (ToF) RGB-D camera\"],\"keywords\":\"$7:props:children:0:props:publications:7:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"IEEE Internet of Things Journal\",\"conference\":\"\",\"volume\":\"11\",\"issue\":\"23\",\"pages\":\"37562-37570\",\"doi\":\"10.1109/JIOT.2024.3434588\",\"abstract\":\"\",\"description\":\"\",\"selected\":false,\"preview\":\"mdivo.png\",\"bibtex\":\"@article{xu2024m,\\n  author = {Xu, Jie and Yu, Wenlu and Huang, Song and Yuan, Shenghai and Zhao, Lijun and Li, Ruifeng and Xie, Lihua},\\n  journal = {IEEE Internet of Things Journal},\\n  title = {M-DIVO: Multiple ToF RGB-D Cameras-Enhanced Depth窶的nertial窶天isual Odometry},\\n  year = {2024},\\n  volume = {11},\\n  number = {23},\\n  pages = {37562-37570},\\n  doi = {10.1109/JIOT.2024.3434588}\\n}\"},{\"id\":\"xu2024selective\",\"title\":\"Selective Kalman Filter: When and How to Fuse Multi-Sensor Information to Overcome Degeneracy in SLAM\",\"authors\":[{\"name\":\"Jie Xu\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Guanyu Huang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Wenlu Yu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xuanxuan Zhang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Lijun Zhao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Ruifeng Li\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Shenghai Yuan\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Lihua Xie\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2024,\"type\":\"journal\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$7:props:children:0:props:publications:8:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"arXiv preprint arXiv:2412.17235\",\"conference\":\"\",\"abstract\":\"\",\"description\":\"\",\"selected\":false,\"preview\":\"selective.png\",\"bibtex\":\"@article{xu2024selective,\\n  title = {Selective Kalman Filter: When and How to Fuse Multi-Sensor Information to Overcome Degeneracy in SLAM},\\n  author = {Xu, Jie and Huang, Guanyu and Yu, Wenlu and Zhang, Xuanxuan and Zhao, Lijun and Li, Ruifeng and Yuan, Shenghai and Xie, Lihua},\\n  journal = {arXiv preprint arXiv:2412.17235},\\n  year = {2024}\\n}\"},{\"id\":\"xu2023r\",\"title\":\"R2DIO: A Robust and Real-Time Depth-Inertial Odometry Leveraging Multimodal Constraints for Challenging Environments\",\"authors\":[{\"name\":\"Jie Xu\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Ruifeng Li\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Song Huang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xiongwei Zhao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Shuxin Qiu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Zhijun Chen\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Lijun Zhao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2023,\"type\":\"journal\",\"status\":\"published\",\"tags\":[\"Simultaneous localization and mapping;Cameras;Robot vision systems;Point cloud compression;Laser radar;Feature extraction;Real-time systems;Dense reconstruction;direction consistency (DC) constraint;indoor simultaneous localization and mapping (SLAM);inertial measurement unit (IMU);multimodal;plane;pseudo 3-D line;RGB-D;time of flight (ToF)\"],\"keywords\":\"$7:props:children:0:props:publications:9:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"IEEE Transactions on Instrumentation and Measurement\",\"conference\":\"\",\"volume\":\"72\",\"issue\":\"\",\"pages\":\"1-11\",\"doi\":\"10.1109/TIM.2023.3320753\",\"code\":\"https://github.com/jiejie567/R2DIO\",\"abstract\":\"\",\"description\":\"\",\"selected\":false,\"preview\":\"r2dio.png\",\"video\":\"https://www.youtube.com/watch?v=YqJZTE948sk\",\"bibtex\":\"@article{xu2023r,\\n  author = {Xu, Jie and Li, Ruifeng and Huang, Song and Zhao, Xiongwei and Qiu, Shuxin and Chen, Zhijun and Zhao, Lijun},\\n  journal = {IEEE Transactions on Instrumentation and Measurement},\\n  title = {R2DIO: A Robust and Real-Time Depth-Inertial Odometry Leveraging Multimodal Constraints for Challenging Environments},\\n  year = {2023},\\n  volume = {72},\\n  number = {},\\n  pages = {1-11},\\n  doi = {10.1109/TIM.2023.3320753},\\n  video = {https://www.youtube.com/watch?v=YqJZTE948sk}\\n}\"},{\"id\":\"xu2022cammap\",\"title\":\"CamMap: Extrinsic Calibration of Non-Overlapping Cameras Based on SLAM Map Alignment\",\"authors\":[{\"name\":\"Jie Xu\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Ruifeng Li\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Lijun Zhao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Wenlu Yu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Zhiheng Liu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Bo Zhang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yuchen Li\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2022,\"type\":\"journal\",\"status\":\"published\",\"tags\":[\"Cameras;Calibration;Simultaneous localization and mapping;Robot vision systems;Pipelines;Synchronization;Robot kinematics;Extrinsic calibration;multiple cameras;non-overlapping FoVs;SLAM\"],\"keywords\":\"$7:props:children:0:props:publications:10:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"IEEE Robotics and Automation Letters\",\"conference\":\"\",\"volume\":\"7\",\"issue\":\"4\",\"pages\":\"11879-11885\",\"doi\":\"10.1109/LRA.2022.3207793\",\"code\":\"https://github.com/jiejie567/SlamForCalib\",\"abstract\":\"\",\"description\":\"\",\"selected\":true,\"preview\":\"cammap.png\",\"video\":\"https://www.bilibili.com/video/BV1XJ4m1T7Qv/?spm_id_from=333.337.search-card.all.click\u0026vd_source=24dbe70b6e5bca1edf14deb9a2f63088\",\"bibtex\":\"@article{xu2022cammap,\\n  author = {Xu, Jie and Li, Ruifeng and Zhao, Lijun and Yu, Wenlu and Liu, Zhiheng and Zhang, Bo and Li, Yuchen},\\n  journal = {IEEE Robotics and Automation Letters},\\n  title = {CamMap: Extrinsic Calibration of Non-Overlapping Cameras Based on SLAM Map Alignment},\\n  year = {2022},\\n  volume = {7},\\n  number = {4},\\n  pages = {11879-11885},\\n  doi = {10.1109/LRA.2022.3207793},\\n  video = {https://www.bilibili.com/video/BV1XJ4m1T7Qv/?spm_id_from=333.337.search-card.all.click\u0026vd_source=24dbe70b6e5bca1edf14deb9a2f63088}\\n}\"}]}],false,false]}]\n"])</script><script>self.__next_f.push([1,"c:null\n"])</script><script>self.__next_f.push([1,"10:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\nb:null\n"])</script><script>self.__next_f.push([1,"14:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Publications | Xu Jie 蠕先擴\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"A collection of my research work.\"}],[\"$\",\"meta\",\"2\",{\"name\":\"author\",\"content\":\"Xu Jie (Rover)\"}],[\"$\",\"meta\",\"3\",{\"name\":\"keywords\",\"content\":\"Xu Jie (Rover),PhD,Research,Nanyang Technological University, Singapore\"}],[\"$\",\"meta\",\"4\",{\"name\":\"creator\",\"content\":\"Xu Jie (Rover)\"}],[\"$\",\"meta\",\"5\",{\"name\":\"publisher\",\"content\":\"Xu Jie (Rover)\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:title\",\"content\":\"Xu Jie 蠕先擴\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:description\",\"content\":\"Research Fellow at Nanyang Technological University, focusing on Embodied AI, SLAM, and multi-sensor fusion.\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:site_name\",\"content\":\"Xu Jie (Rover)'s Academic Website\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"11\",{\"name\":\"twitter:card\",\"content\":\"summary\"}],[\"$\",\"meta\",\"12\",{\"name\":\"twitter:title\",\"content\":\"Xu Jie 蠕先擴\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:description\",\"content\":\"Research Fellow at Nanyang Technological University, focusing on Embodied AI, SLAM, and multi-sensor fusion.\"}],[\"$\",\"link\",\"14\",{\"rel\":\"icon\",\"href\":\"/favicon.svg\"}]],\"error\":null,\"digest\":\"$undefined\"}\ne:{\"metadata\":\"$14:metadata\",\"error\":null,\"digest\":\"$undefined\"}\n"])</script></body></html>